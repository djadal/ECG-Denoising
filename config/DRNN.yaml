train:
  epochs: 200
  batch_size: 128
  optimizer:
    type: "Adam"
    lr: 0.001

  lr_scheduler:
    use: true
    type: "ReduceLROnPlateau"
    factor: 0.5
    min_delta: 0.05
    mode: "min"
    patience: 2
    min_lr: 1e-10
    verbose: true

  early_stopping:
    use: true
    min_delta: 0.05
    mode: "min"
    patience: 10
    verbose: true
  criterion: "MSELoss"

model:
  input_size: 1
  hidden_size: 64
  num_layers: 1

test:
  batch_size: 32